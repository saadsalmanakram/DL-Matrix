# ReLU Activation
relu = nn.ReLU()

# Softmax Activation (used for classification)
softmax = nn.Softmax(dim=1)
